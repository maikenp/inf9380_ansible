# THIS FILE IS CONTROLLED BY ANSIBLE
# It will be overwritten if the ansible playbook is rerun
# Any changes should go in the ansible template file. 

##############################
# GENERAL
##############################
ClusterName={{ slurm_cluster_name }}
ControlMachine={{ master_name }}
ControlAddr={{ master_ip }}
SlurmUser=slurm
SlurmctldPort={{ slurmctldport }}
SlurmdPort=6818
AuthType=auth/munge
StateSaveLocation=/var/spool/slurm/ctld
SlurmdSpoolDir=/var/spool/slurm/d
SwitchType=switch/none
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmdPidFile=/var/run/slurmd.pid
ProctrackType=proctrack/pgid
ReturnToService=0

##############################
# TIMERS
##############################
SlurmctldTimeout=300
SlurmdTimeout=300
InactiveLimit=0
MinJobAge=300
KillWait=30
Waittime=0
MessageTimeout=30

###############################
# SCHEDULING
##############################
SchedulerType=sched/backfill
SelectType=select/cons_res
SelectTypeParameters=CR_CPU_Memory
PreemptMode=requeue
PreemptType=preempt/qos

#In order to try to fill up nodes, hopefully single core jobs get packed into nodes with
# space rather than using a new node                                                                 
SchedulerParameters=pack_serial_at_end
DefMemPerCPU=2500


##############################
# LOGGING
##############################
SlurmctldDebug=info
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdDebug=info
SlurmdLogFile=/var/log/slurm/slurmd.log
JobCompType=jobcomp/none
DebugFlags=backfill,cpu_bind,priority,reservation,selecttype,steps,NO_CONF_HASH


{% if 'db' in ansible_skip_tags %}
{% else %}
##############################
# ACCOUNTING
##############################
AccountingStorageType=accounting_storage/slurmdbd
AccountingStorageEnforce=associations,limits,qos
AccountingStoreJobComment=YES
AccountingStorageHost={{ master_name }}
AccountingStoragePort=6819

JobAcctGatherType=jobacct_gather/linux
JobAcctGatherFrequency=30
{% endif %}


##############################
# COMPUTE NODES
##############################
Include /etc/slurm/slurmnodes.conf

